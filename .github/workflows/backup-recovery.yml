name: Backup & Recovery

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Type of backup'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - incremental
        - test-restore

jobs:
  database-backup:
    name: Database Backup
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS CLI
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region ${{ secrets.AWS_REGION }}

    - name: Create database backup
      run: |
        # This would typically connect to the database and create a backup
        # For demonstration, we'll create a timestamped backup file
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        BACKUP_FILE="backup_${TIMESTAMP}.sql"

        # In a real scenario, this would be:
        # pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME > $BACKUP_FILE

        echo "Creating backup: $BACKUP_FILE"
        echo "-- Database backup created at $(date)" > $BACKUP_FILE
        echo "-- This is a placeholder backup file" >> $BACKUP_FILE

    - name: Compress backup
      run: |
        gzip $BACKUP_FILE

    - name: Upload to S3
      run: |
        aws s3 cp ${BACKUP_FILE}.gz s3://${{ secrets.BACKUP_BUCKET }}/database/${BACKUP_FILE}.gz

    - name: Clean up local files
      run: |
        rm -f $BACKUP_FILE.gz

    - name: Verify backup integrity
      run: |
        # Download and verify the backup
        aws s3 cp s3://${{ secrets.BACKUP_BUCKET }}/database/${BACKUP_FILE}.gz /tmp/
        gunzip /tmp/${BACKUP_FILE}.gz
        # In a real scenario, you would verify the backup can be restored

  configuration-backup:
    name: Configuration Backup
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS CLI
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region ${{ secrets.AWS_REGION }}

    - name: Backup Kubernetes configurations
      run: |
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        BACKUP_DIR="config_backup_${TIMESTAMP}"

        mkdir -p $BACKUP_DIR

        # Backup k8s manifests
        cp -r k8s/ $BACKUP_DIR/

        # Backup environment configurations
        cp docker-compose*.yml $BACKUP_DIR/ 2>/dev/null || true
        cp .env.example $BACKUP_DIR/ 2>/dev/null || true

    - name: Create archive
      run: |
        tar -czf ${BACKUP_DIR}.tar.gz $BACKUP_DIR

    - name: Upload to S3
      run: |
        aws s3 cp ${BACKUP_DIR}.tar.gz s3://${{ secrets.BACKUP_BUCKET }}/config/${BACKUP_DIR}.tar.gz

    - name: Clean up
      run: |
        rm -rf $BACKUP_DIR ${BACKUP_DIR}.tar.gz

  test-recovery:
    name: Test Recovery
    runs-on: ubuntu-latest
    if: inputs.backup_type == 'test-restore'

    steps:
    - name: Configure AWS CLI
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region ${{ secrets.AWS_REGION }}

    - name: List recent backups
      run: |
        aws s3 ls s3://${{ secrets.BACKUP_BUCKET }}/database/ --recursive | tail -5

    - name: Test restore procedure
      run: |
        # Download latest backup
        LATEST_BACKUP=$(aws s3 ls s3://${{ secrets.BACKUP_BUCKET }}/database/ --recursive | sort | tail -1 | awk '{print $4}')
        aws s3 cp s3://${{ secrets.BACKUP_BUCKET }}/$LATEST_BACKUP /tmp/

        # Test decompression
        gunzip /tmp/$(basename $LATEST_BACKUP)

        echo "Recovery test completed successfully"

  cleanup-old-backups:
    name: Cleanup Old Backups
    runs-on: ubuntu-latest

    steps:
    - name: Configure AWS CLI
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region ${{ secrets.AWS_REGION }}

    - name: Remove backups older than 30 days
      run: |
        # Remove old database backups
        aws s3 ls s3://${{ secrets.BACKUP_BUCKET }}/database/ --recursive | \
        awk '$1 < "'$(date -d '30 days ago' +%Y-%m-%d)'" {print $4}' | \
        xargs -I {} aws s3 rm s3://${{ secrets.BACKUP_BUCKET }}/{} || true

        # Remove old config backups
        aws s3 ls s3://${{ secrets.BACKUP_BUCKET }}/config/ --recursive | \
        awk '$1 < "'$(date -d '30 days ago' +%Y-%m-%d)'" {print $4}' | \
        xargs -I {} aws s3 rm s3://${{ secrets.BACKUP_BUCKET }}/{} || true

  notify-backup-status:
    name: Notify Backup Status
    runs-on: ubuntu-latest
    needs: [database-backup, configuration-backup, cleanup-old-backups]
    if: always()

    steps:
    - name: Send notification
      run: |
        if [ "${{ needs.database-backup.result }}" = "success" ] && [ "${{ needs.configuration-backup.result }}" = "success" ]; then
          echo "✅ All backups completed successfully"
        else
          echo "❌ Some backups failed. Please check the logs."
        fi